---
title: "Untitled"
output: html_document
---
# 1.0 LIBRARIES ----
```{r}
# Modeling
library(survival)
library(parsnip)
library(broom)

# Advanced ML
library(h2o)
library(lime)

# EDA
library(correlationfunnel)

# Core & Data Viz
library(tidyverse)
library(plotly)
library(tidyquant)
```


```{r}
# Check H2O Version to match Model Version
source("scripts/check_h2o_version.R")
```

# 2.0 DATA ----
```{r}

# - KEY POINTS: tenure = Time, Churn = Target, Everything Else = Possible Predictors

customer_churn_tbl <- read_csv("~/Data_science/Git/R_project/Churn/lab_14_customer_churn_survival_h2o/WA_Fn-UseC_-Telco-Customer-Churn.csv")

customer_churn_tbl %>% glimpse()
```

# 3.0 EXPLORATORY DATA ANALYSIS ----
```{r}

# - Use my new correlationfunnel package!

#customer_churn_tbl %>% correlationfunnel::binarize()
```
Error: binarize(): [Missing Values Detected] The following columns contain NAs: TotalCharges

```{r}
# Check NA's - purrr/dplyr Data Wrangling
customer_churn_tbl %>%
    map_df(~ sum(is.na(.))) %>%
    gather() %>%
    arrange(desc(value))
```


```{r}
customer_churn_tbl %>%
    filter(is.na(TotalCharges)) %>%
    glimpse()
```

# Prep Data: Remove non-predictive ID & fix NA's
```{r}

customer_churn_prep_tbl <- customer_churn_tbl %>%
    select(-customerID) %>%
    mutate(TotalCharges = case_when(
        is.na(TotalCharges) ~ MonthlyCharges, # if na --> value = MonthlyCharges, if not na, value = TotalCharges
        TRUE ~ TotalCharges
    )) 
customer_churn_prep_tbl
```

```{r}
customer_churn_prep_tbl %>%
    binarize() 
```
# Correlation Funnel 
```{r}

customer_churn_prep_tbl %>%
    binarize() %>%
    correlate(Churn__Yes) %>% 
    plot_correlation_funnel(interactive = TRUE, alpha = 0.7)
# tenure = Time, Churn = Target, Everything Else = Possible Predictors
```

# 4.0 SURVIVAL ANALYSIS ----
```{r}
customer_churn_prep_tbl %>%
    binarize() %>%
    correlate(Churn__Yes)
```

```{r}
# Select only 
train_tbl <- customer_churn_prep_tbl %>%
    mutate(
        Churn_Yes                     = Churn == "Yes",
        OnlineSecurity_No             = OnlineSecurity == "No",
        TechSupport_No                = TechSupport == "No",
        InternetService_FiberOptic    = InternetService %>% str_detect("Fiber"),
        PaymentMethod_ElectronicCheck = PaymentMethod %>% str_detect("Electronic"),
        OnlineBackup_No               = OnlineBackup == "No",
        DeviceProtection_No           = DeviceProtection == "No"
    ) %>%
    select(
        tenure, Churn_Yes, Contract, OnlineSecurity_No, TechSupport_No, InternetService_FiberOptic,
        PaymentMethod_ElectronicCheck, OnlineSecurity_No, DeviceProtection_No
    ) 
train_tbl
```


```{r}
# 4.1 Survival Tables (Kaplan-Meier Method) ----
survfit_simple <- survfit(Surv(tenure, Churn_Yes) ~ strata(Contract), data = train_tbl)
survfit_simple
```


```{r}
# Mortality Table
tidy(survfit_simple)
```

```{r}
# 4.2 Cox Regression Model (Multivariate) ----
model_coxph <- coxph(Surv(tenure, Churn_Yes) ~ . - Contract + strata(Contract), data = train_tbl)
model_coxph
```

```{r}
# Overall performance
glance(model_coxph) %>% glimpse()
```

```{r}
# Regression Estimates
tidy(model_coxph)
```

```{r}
# Mortality Table
model_coxph %>%
    survfit() %>%
    tidy()

```
# 5.0 SURVIVAL CURVES -----

```{r}
plot_customer_survival <- function(object_survfit) {
    
    g <- tidy(object_survfit) %>%
        ggplot(aes(time, estimate, color = strata)) +
        geom_ribbon(aes(ymin = conf.low, ymax = conf.high), alpha = 0.5) +
        geom_line(size = 1) +
        theme_tq() +
        scale_color_tq() +
        scale_y_continuous(labels = scales::percent_format()) +
        labs(title = "Churn Problem", color = "Contract Type", 
             x = "Days After Purchase", y = "Percentage of Customers Staying")
    
    ggplotly(g)
}

plot_customer_survival(survfit_simple)
```


```{r}
survfit_coxph <- survfit(model_coxph)
plot_customer_survival(survfit_coxph)
```


```{r}
plot_customer_loss <- function(object_survfit) {
    
    g <- tidy(object_survfit) %>%
        mutate(customers_lost = 1 - estimate) %>%
        ggplot(aes(time, customers_lost, color = strata)) +
        geom_line(size = 1) +
        theme_tq() +
        scale_color_tq() +
        scale_y_continuous(labels = scales::percent_format()) +
        labs(title = "Churn Problem", color = "Contract Type", 
             x = "Days After Purchase", y = "Percentage of Customers Lost")
    
    ggplotly(g)
}

plot_customer_loss(survfit_simple)
```


```{r}
plot_customer_loss(survfit_coxph)
```

# 6.0 PREDICTION with Survial Models ----
```{r}
# 6.1 Cox PH - Produces Theoretical Hazard Ratio ----
predict(model_coxph, newdata = train_tbl, type = "expected") %>%
    tibble(.pred = .) %>%
    bind_cols(train_tbl)
```


```{r}
# 6.2 Survival Regression w/ Parsnip ----
model_survreg <- parsnip::surv_reg(mode = "regression", dist = "weibull") %>%
    #set_engine("survreg", control = survreg.control(maxiter=500)) %>% # survreg not available
    set_engine("survival", control = survreg.control(maxiter=500)) %>%
    fit.model_spec(Surv(I(tenure + 1), Churn_Yes) ~ . - Contract + strata(Contract), data = train_tbl)
model_survreg
```
```{r}
model_survreg$fit %>% tidy()
```

```{r}
# model_survreg$fit %>% survfit() # Get an error (not as convenient as CoxPH for getting survival curves)
```
Error in UseMethod("survfit") : no applicable method for 'survfit' applied to an object of class "survreg"
```{r}
predict(model_survreg, new_data = train_tbl) %>%
    bind_cols(train_tbl %>% select(Churn_Yes, everything()))
```

```{r}
# SUMMARY:
# 6.1 CoxPH 
#   - Let's us use multivariate regression
# 6.2 Survival Curve
#   - Curves give us a clear indication of how cohorts churn
#   - We saw that if someone is Month-to-Month Contract, that group is 48% risk of leaving in first 50 days
# 6.3 Survival Regression 
#   - Gives us estimated time, but can be quite innaccurate

# CONCLUSION:
# 1. Survival curves help understand time-dependent churn rates
# 2. NEED Better Method that Describes Each Individual Accurately --> Machine Learning
```

# 7.0 MACHINE LEARNING FOR CHURN RISK ----
```{r}
# 7.1 H2O ----
# - Use H2O to Develop ML Models (DS4B 201-R)
# - 27 ML Models in 90 seconds
# - Take 201 to learn H2O
```

```{r}
#install.packages("tictoc")\
library(tidyverse)
library(data.table)
library(caret)     # for model packages
library(h2o)
library(recipes)
library(tictoc)
```
## Recipe
```{r}
data <- fread("~/Data_science/Git/R_project/Churn/lab_14_customer_churn_survival_h2o/WA_Fn-UseC_-Telco-Customer-Churn.csv")
str(data)
```
```{r}
table(data$Churn)
prop.table(table(data$Churn))
```

```{r}
# Prep Data: Remove non-predictive ID & fix NA's
data_prep_tbl <- data %>%
    select(-customerID) %>%
    mutate(TotalCharges = case_when(
        is.na(TotalCharges) ~ MonthlyCharges,
        TRUE ~ TotalCharges
    ))
#data_prep_tbl
```
```{r}
h2o.init()
```

```{r}

response="Churn"
set.seed(430)
split = caret::createDataPartition(data[[response]], p =0.6, list = FALSE)
train = data[split, ]

valid_test = data[-split, ]
split2 = caret::createDataPartition(valid_test[[response]], p =0.5, list = FALSE)
valid = valid_test[split2, ]
test = valid_test[-split2, ]

dim(train)
dim(valid)
dim(test)
prop.table(table(as.data.frame(train[[response]])))
prop.table(table(as.data.frame(valid[[response]])))
prop.table(table(as.data.frame(test[[response]])))

recipe_obj <- recipe(Churn ~ ., data = train) %>%
  step_rm(customerID) %>% 
  step_string2factor(all_nominal()) %>% # convert character to factor (auto convert char to factor with recipes)
  #step_integer(Education,EnvironmentSatisfaction) %>% # Ordinal encoder
  #step_num2factor(Education,EnvironmentSatisfaction,JobInvolvement,JobLevel,JobSatisfaction,PerformanceRating,RelationshipSatisfaction,StockOptionLevel,WorkLifeBalance) %>%  # convert number to factor
  step_nzv(all_numeric(), -all_outcomes())  %>% #Remove near-zero variance features like sex, yes/no...
  #step_knnimpute(all_predictors(), neighbors = 6) %>%  # Impute, very slow in large data in train, need step outside
  #step_YeoJohnson(all_numeric(),-all_outcomes()) %>% # Remove skewness
  
  #step_center(all_numeric(), -all_outcomes()) %>% # center 
  #step_scale(all_numeric(), -all_outcomes()) %>% # scale
  #step_dummy(all_nominal(), one_hot = TRUE) %>% 
  #step_pca(all_numeric(), -all_outcomes()) #Perform dimension reduction
  prep()
baked_train <- bake(recipe_obj, new_data = train)
baked_valid <- bake(recipe_obj, new_data = valid)
baked_test <- bake(recipe_obj, new_data = test)
# convert training data to h2o object
train_h2o <- as.h2o(baked_train)
valid_h2o <- as.h2o(baked_valid)
test_h2o <- as.h2o(baked_test)
# set the predictor names
predictors <- setdiff(colnames(baked_train), response)

sum(is.na(train))
sum(is.na(baked_train))
```
## Base model
### GBM
```{r}
assignment_type <- "Stratified"
tic()
h2o.gbm <- h2o.gbm(
    x = predictors, 
    y = response,
    training_frame = train_h2o, 
    validation_frame = valid_h2o,
    balance_classes = TRUE,
    #fold_assignment = assignment_type,
    #ntrees = 1000,
    #booster = "dart",
    #normalize_type = "tree",
    #nfolds=5,
    seed = 123
)
toc() # 7 s
test_pred <-h2o.predict(h2o.gbm, newdata = test_h2o)
predict <- as.data.frame(test_pred)$predict
reference <- as.data.frame(test_h2o)[[response]]
caret::confusionMatrix(predict,reference,positive = "Yes",mode="prec_recall")
```
```{r}
# BEST
assignment_type <- "Stratified"
tic()
h2o.gbm <- h2o.gbm(
    x = predictors, 
    y = response,
    training_frame = train_h2o, 
    #validation_frame = valid_h2o,
    balance_classes = TRUE,
    fold_assignment = assignment_type,
    nfolds=5,
    #ntrees = 1000,
    #booster = "dart",
    #normalize_type = "tree",
    
    seed = 123
)
toc() # 7 s
test_pred <-h2o.predict(h2o.gbm, newdata = test_h2o)
predict <- as.data.frame(test_pred)$predict
reference <- as.data.frame(test_h2o)[[response]]
caret::confusionMatrix(predict,reference,positive = "Yes",mode="prec_recall")
```
```{r}
assignment_type <- "Stratified"
# you can also try "Auto", "Modulo", and "Stratified"
h2o_gbm <- h2o.gbm(
  ## standard model parameters
  x = predictors,
  y = response,
  training_frame = train_h2o,
  #fold_assignment = assignment_type,
  #nfolds=5,
  validation_frame = valid_h2o,
  ## more trees is better if the learning rate is small enough
  ## here, use "more than enough" trees - we have early stopping
  ntrees = 10000,
  ## smaller learning rate is better (this is a good value for most datasets, but see below for annealing)
  learn_rate=0.02,
  ## early stopping once the validation AUC doesn't improve by at least 0.01% for 5 consecutive scoring events
  stopping_rounds = 5, stopping_tolerance = 1e-4, stopping_metric = "AUC",
  ## sample 80% of rows per tree
  sample_rate = 0.8,
  ## sample 80% of columns per split
  col_sample_rate = 0.8,
  ## fix a random number generator seed for reproducibility
  seed = 1234,
  ## score every 10 trees to make early stopping reproducible (it depends on the scoring interval)
  #score_tree_interval = 10
)
test_pred <-h2o.predict(h2o_gbm, newdata = test_h2o)
predict <- as.data.frame(test_pred)$predict
reference <- as.data.frame(test_h2o)[[response]]
caret::confusionMatrix(predict,reference,positive = "Yes",mode="prec_recall")
```
### RANDOM FOREST
```{r}
assignment_type <- "Stratified"
tic()
h2o_model_rf <- h2o.randomForest(
    x = predictors, 
    y = response,
    training_frame = train_h2o, 
    validation_frame = valid_h2o,
    balance_classes = TRUE,
    ntrees = 1000,
    #fold_assignment = assignment_type,
    #nfolds=5,
    seed = 123
)
toc() # 7 s
test_pred <-h2o.predict(h2o_model_rf, newdata = test_h2o)
predict <- as.data.frame(test_pred)$predict
reference <- as.data.frame(test_h2o)[[response]]
caret::confusionMatrix(predict,reference,positive = "Yes",mode="prec_recall")
```
### Light GBM
```{r}
# Light gbm
assignment_type <- "Stratified"
tic()
h2o_model_lightgbm <- h2o.xgboost(
    x = predictors, 
    y = response,
    training_frame = train_h2o, 
    validation_frame = valid_h2o,
    #fold_assignment = assignment_type,
    tree_method="hist",
    grow_policy="lossguide",
    #nfolds=5,
    seed = 123
)
toc() # 7 s
test_pred <-h2o.predict(h2o_model_lightgbm, newdata = test_h2o)
predict <- as.data.frame(test_pred)$predict
reference <- as.data.frame(test_h2o)[[response]]
caret::confusionMatrix(predict,reference,positive = "Yes",mode="prec_recall")
```

## Save model
```{r}

# Save recipe
#write_rds(recipe_obj,"recipe.Rds")

#Save model
#slect_model=h2o.gbm
#getwd()
#model_path <- h2o.saveModel(object = slect_model, path = getwd(), force = TRUE)
print(model_path)
```

## Load model
```{r}
#path <- "WA_Fn-UseC_-HR-Employee-Attrition.csv"
# Load recipe
#recipe_load <- readr::read_rds("/home/dnn/Data_science/Git/R_project/Churn/GBM_model_R_1613221099274_388/recipe.Rds")
# Load model
model_path <- "/home/dnn/Data_science/Git/R_project/Churn/GBM_model_R_1613221099274_388"
h2o_model_load <- h2o.loadModel(model_path)
```

## Model explain
```{r}
h2o.varimp(h2o_model_load)
```


```{r}
h2o.varimp_plot(h2o_model_load)
```


```{r}
h2o.shap_summary_plot(h2o_model_load,test_h2o)
```


```{r}
h2o.pd_plot(h2o_model_load, test_h2o, column = "Contract")
h2o.pd_plot(h2o_model_load, test_h2o, column = "tenure")
h2o.pd_plot(h2o_model_load, test_h2o, column = "MonthlyCharges")
h2o.pd_plot(h2o_model_load, test_h2o, column = "OnlineSecurity")
h2o.pd_plot(h2o_model_load, test_h2o, column = "PaymentMethod")
```


```{r}
# built-in PDP support in H2O
h2o.partialPlot(h2o_model_load, data = test_h2o, cols = "MonthlyCharges")
```
```{r}
h2o.ice_plot(h2o_model_load, test_h2o, column = "MonthlyCharges")
```

```{r}
# Class = No
h2o.shap_explain_row_plot(h2o_model_load, test_h2o,row_index = 10)
h2o.shap_explain_row_plot(h2o_model_load, test_h2o,row_index = 3)
# Class =Yes #2,17,20
h2o.shap_explain_row_plot(h2o_model_load, test_h2o,row_index = 18)
h2o.shap_explain_row_plot(h2o_model_load, test_h2o,row_index = 4)
```

```{r}
train_h2o[,-1]
```

```{r}
library(lime)
# Run lime() on training set
explainer <- lime::lime(
    as.data.frame(train_h2o) %>% drop_na(), 
    model          = h2o_model_load, 
    bin_continuous = FALSE)
# Run explain() on explainer
explanation <- lime::explain(
    as.data.frame(test_h2o[1,]), 
    explainer    = explainer, 
    n_labels     = 1, 
    n_features   = 10,
    kernel_width = 0.5)
lime::plot_features(explanation) +
      labs(title = "HR Predictive Analytics: LIME Feature Importance Visualization",
           subtitle = "Hold Out (Test) Set, First 10 Cases Shown")
```


```{r}
```

## Auto ML:
```{r}
h2o.init()
# convert training data to h2o object
train_h2o <- as.h2o(baked_train)
test_h2o <- as.h2o(baked_test)

#n_features <- length(setdiff(names(train_h2o),response))
predictors <- setdiff(colnames(train_h2o), response)
```

```{r}
tic()
auto_ml <- h2o.automl(
    x = predictors, 
    y = response,
    training_frame = train_h2o,
    #leaderboard_frame = h2o_validation,
    project_name = response,
    max_runtime_secs = 90,
    #max_models = 10, #10
    seed = 12
)
toc()
auto_ml
```

```{r}
model_ids <- as.data.frame(auto_ml@leaderboard$model_id)[,1]
# Check performance GBM autoML
slect_model <- h2o.getModel(model_ids[1])
test_pred <- h2o.predict(slect_model, test_h2o) 
reference <- as.data.frame(test_h2o)[[response]]
predict <- as.data.frame(test_pred)$predict
caret::confusionMatrix(predict,reference,positive = "Yes",mode="prec_recall")
```

```{r}
```


```{r}
```


```{r}
```


```{r}
```

