---
title: "Job_attrition"
output: html_document
---
# 1. Import Data
```{r}
#library(tidyverse)# include dplyr, tidr, ggplot2, tibble, readr, purr
library(dplyr) # mutate, select, filter, summarize, arrange, group by 
library(tidyr) # gather, spread, separate, extract, unite, %>%
library(ggplot2)
library(tibble) # provide tibble class (better than traditional data frame)
library(readr) # read_csv, tsv, delim, table, log....
library(purrr) # map, map_dbl, split,
library(data.table)
library(rsample)   # for data splitting
library(caret)     # for model packages
```

```{r}
path="WA_Fn-UseC_-HR-Employee-Attrition.csv"
data <- fread(path)
data
```
# 2. Summary of data:

Questions we could Ask Ourselves:
- Columns and Observations: How many columns and observations is there in our dataset?
- Missing data: Are there any missing data in our dataset?
- Data Type: The different datatypes we are dealing in this dataset.
- Distribution of our Data: Is it right-skewed, left-skewed or symmetric? This might be useful especially if we are implementing any type of statistical analysis or even for modelling.
- Structure of our Data: Some datasets are a bit complex to work with however, the tidyverse package is really useful to deal with complex datasets.
- Meaning of our Data: What does our data mean? Most features in this dataset are ordinal variables which are similar to categorical variables however, ordering of those variables matter. A lot of the variables in this dataset have a range from 1-4 or 1-5, The lower the ordinal variable, the worse it is in this case. For instance, Job Satisfaction 1 = "Low" while 4 = "Very High".
- Label: What is our label in the dataset or in otherwords the output?
```{r}
#class(data)
#dim(data)
#str(data)
```

```{r}
# Using an insightful summary with skim and kable
data %>% glimpse()
```

```{r}
summary(data)
```

```{r}
psych::describe(data)
```
# Check Null value

```{r}
sum(is.na(data))
```


```{r}
#install.packages("Tmisc")
library(Tmisc)
Tmisc::gg_na(data)
```


```{r}
Tmisc::propmiss(data)
```
# Distribution of our Labels:
```{r}
#install.packages("cowplot")
library(cowplot)
```

```{r}
options(repr.plot.width=8, repr.plot.height=4)

# plot count
attritions_number <- data %>% 
                    group_by(Attrition) %>% 
                    summarise(Count=n()) %>%
ggplot(aes(x=Attrition, y=Count)) + geom_bar(stat="identity", fill="orange", color="grey40") + theme_bw() + coord_flip() + 
geom_text(aes(x=Attrition, y=0.01, label= Count),
            hjust=-0.8, vjust=-1, size=3, 
            colour="black", fontface="bold",
         angle=360) + labs(title="Employee Attrition (Amount)", x="Employee Attrition",y="Amount") + theme(plot.title=element_text(hjust=0.5))

# plot percentage
attrition_percentage <- data %>% group_by(Attrition) %>%
                                  summarise(Count=n()) %>% 
                                  mutate(pct=round(prop.table(Count),2) * 100) %>% 
ggplot(aes(x=Attrition, y=pct)) + geom_bar(stat="identity", fill = "dodgerblue", color="grey40") + 
geom_text(aes(x=Attrition, y=0.01, label= sprintf("%.2f%%", pct)),
            hjust=0.5, vjust=-3, size=4, 
            colour="black", fontface="bold") + theme_bw() + labs(x="Employee Attrition", y="Percentage") + 
labs(title="Employee Attrition (%)") + theme(plot.title=element_text(hjust=0.5))

cowplot::plot_grid(attritions_number, attrition_percentage, align="h", ncol=2)
```

```{r}
count(data,Attrition)
```
# 3. Data analysis/visualization

```{r}
ggplot(data,aes(x = Age,fill = Attrition)) +
  geom_density(alpha = 0.4) 
```

```{r}
head(data)
```

```{r}
ggplot(data,aes(x = Attrition,y = Age,fill=Attrition)) +
  geom_boxplot(alpha = 0.4) 
```


```{r}
ggplot(data, aes(x = BusinessTravel)) + 
  geom_bar()
```
```{r}
count(data,BusinessTravel)
```
```{r}
#install.packages("memisc")
library(memisc)
memisc::percent(data$BusinessTravel)
```



```{r}
ggplot(data, 
       aes(x = BusinessTravel, 
           y = ..count.. / sum(..count..))) + 
  geom_bar()
```


```{r}
plotdata <- data %>%
  count(BusinessTravel) %>%
  mutate(pct = n / sum(n),
         pctlabel = paste0(round(pct*100), "%"))
plotdata
```


```{r}
library(scales)
ggplot(plotdata, 
       aes(x = reorder(BusinessTravel, -pct),
           y = pct)) + 
  geom_bar(stat = "identity", 
           #fill = "indianred3", 
           color = "black") +
  geom_text(aes(label = pctlabel), 
            vjust = -0.25) +
  scale_y_continuous(labels = percent) +
  labs(x = "Race", 
       y = "Percent", 
       title  = "Participants by race")
```

```{r}
# create a summary dataset
library(dplyr)
plotdata <- data %>%
  group_by(Attrition, BusinessTravel) %>%
  summarize(n = n()) %>% 
  mutate(pct = n/sum(n),
         lbl = scales::percent(pct))
plotdata
```


```{r}
# create segmented bar chart
# adding labels to each segment

ggplot(plotdata, 
       aes(x = Attrition,
           y = pct,
           fill = BusinessTravel)) + 
  geom_bar(stat = "identity",
           position = "fill") +
  scale_y_continuous(breaks = seq(0, 1, .2),label = percent) +
  geom_text(aes(label = lbl), 
            size = 3, 
            position = position_stack(vjust = 0.5)) +
  scale_fill_brewer(palette = "Set2") +
  #labs(y = "Percent",fill = "Drive Train",x = "Class",title = "Automobile Drive by Class") +
  theme_minimal()
```
# 3.1 Plot categorical vs catagorical

```{r}
data %>%
  dplyr::group_by(Attrition, BusinessTravel) %>%
  dplyr::summarize(n = n()) %>% 
  dplyr::mutate(pct = n/sum(n),lbl = scales::percent(pct)) %>% 
  ggplot(aes(x = Attrition,y = pct,
           fill = BusinessTravel)) + 
  geom_bar(stat = "identity",
           position = "fill") +
  scale_y_continuous(breaks = seq(0, 1, .2),label = percent) +
  geom_text(aes(label = lbl), 
            size = 3, 
            position = position_stack(vjust = 0.5)) +
  scale_fill_brewer(palette = "Set2") +
  #labs(y = "Percent",fill = "Drive Train",x = "Class",title = "Automobile Drive by Class") +
  theme_minimal()
```

```{r}
Categorical_vs_categorical_plot <- function(data,group_col,fill_col){
data %>%
  group_by_(group_col, fill_col) %>%
  summarize(n = n()) %>% 
  mutate(pct = n/sum(n),lbl = scales::percent(pct))%>% 
  ggplot(aes_(x = group_col,y = ~pct,
           fill = fill_col)) +
  geom_bar(stat = "identity",
           position = "fill") +
  scale_y_continuous(breaks = seq(0, 1, .2),label = percent) +
  geom_text(aes(label = lbl), 
            size = 3, 
            position = position_stack(vjust = 0.5)) +
  #scale_fill_brewer(palette = "Set2") +
  labs(y = "Percent",x = "Attrition",title = "Compare attrition accross category")+
  theme_minimal()  
  
}
```

```{r}
# Get all character columns
data %>% 
  select_if(is.character)
```

```{r}
Categorical_vs_categorical_plot(data,~Attrition,~BusinessTravel)
Categorical_vs_categorical_plot(data,~Attrition,~Department)
Categorical_vs_categorical_plot(data,~Attrition,~EducationField)
Categorical_vs_categorical_plot(data,~Attrition,~Gender)
Categorical_vs_categorical_plot(data,~Attrition,~JobRole)
Categorical_vs_categorical_plot(data,~Attrition,~MaritalStatus)
Categorical_vs_categorical_plot(data,~Attrition,~OverTime)

```

# Combine multy plot
```{r}
#install.packages("patchwork")
library(patchwork)
p1 <- Categorical_vs_categorical_plot(data,~Attrition,~BusinessTravel)
p2 <- Categorical_vs_categorical_plot(data,~Attrition,~Department)
p3 <- Categorical_vs_categorical_plot(data,~Attrition,~EducationField)
```


```{r}
#install.packages("gridExtra")
library(gridExtra)
gridExtra::grid.arrange(p1,p2,p3)
```

# 3.2 Plot Quantitative vs. Quantitative

```{r}
str(data)
```


```{r}
# plot the distribution of salaries 
# by rank using kernel density plots
ggplot(data, 
       aes(x = DistanceFromHome, 
           fill = Attrition)) +
  geom_density(alpha = 0.4) 
  #labs(title = "Salary distribution by rank")
```

```{r}
#install.packages("ggridges")
library(ggridges)

ggplot(data, 
       aes(x = DistanceFromHome, 
           y = Attrition, 
           fill = Attrition)) +
  geom_density_ridges() + 
  theme_ridges() +
  theme(legend.position = "none")
```

```{r}
# plot the distribution of salaries by rank using boxplots
ggplot(data, 
       aes(x = Attrition, 
           y = DistanceFromHome)) +
  geom_boxplot() 
  #labs(title = "Salary distribution by rank")

# plot the distribution using violin and boxplots
ggplot(data, aes(x = Attrition, 
                     y = DistanceFromHome)) +
  geom_violin(fill = "cornflowerblue") +
  geom_boxplot(width = .2, 
               fill = "orange",
               outlier.color = "orange",
               outlier.size = 2) 
```
```{r}
ggplot(data, 
       aes(x = EnvironmentSatisfaction, 
           fill = Attrition)) +
  geom_density(alpha = 0.4) 
```


```{r}
ggplot(data, 
       aes(x = Attrition, 
           y = EnvironmentSatisfaction)) +
  geom_boxplot() 

# plot the distribution using violin and boxplots
ggplot(data, aes(x = Attrition, 
                     y = EnvironmentSatisfaction)) +
  geom_violin(fill = "cornflowerblue") +
  geom_boxplot(width = .2, 
               fill = "orange",
               outlier.color = "orange",
               outlier.size = 2) 

```
```{r}
ggplot(data, aes(x = Attrition, 
                     y = MonthlyIncome)) +
  geom_violin(fill = "cornflowerblue") +
  geom_boxplot(width = .2, 
               fill = "orange",
               outlier.color = "orange",
               outlier.size = 2) +
  facet_wrap(~Department) 
```
```{r}
ggplot(data, aes(x = Attrition, 
                     y = MonthlyIncome)) +
  geom_violin(fill = "cornflowerblue") +
  geom_boxplot(width = .2, 
               fill = "orange",
               outlier.color = "orange",
               outlier.size = 2) +
  facet_wrap(~JobRole) 
```
```{r}
ggplot(data, aes(x = Attrition, 
                     y = MonthlyIncome)) +
  geom_violin(fill = "cornflowerblue") +
  geom_boxplot(width = .2, 
               fill = "orange",
               outlier.color = "orange",
               outlier.size = 2) +
  facet_wrap(~JobSatisfaction) 
```
```{r}
ggplot(data, aes(x = Attrition, 
                     y = MonthlyIncome)) +
  geom_violin(fill = "cornflowerblue") +
  geom_boxplot(width = .2, 
               fill = "orange",
               outlier.color = "orange",
               outlier.size = 2) +
  facet_wrap(~PerformanceRating) 
```

```{r}
Categorical_vs_quantitative_plot <- function(data,categorical_col,quantitative_col){
  # plot the distribution using violin and boxplots
  ggplot(data, aes_(x = categorical_col, 
                     y = quantitative_col)) +
  geom_violin(fill = "cornflowerblue") +
  geom_boxplot(width = .2, 
               fill = "orange",
               outlier.color = "orange",
               outlier.size = 2) 
}
```

```{r}
data %>% 
  select_if(is.numeric)
```


```{r}
Categorical_vs_quantitative_plot(data,~Attrition,~Age)
Categorical_vs_quantitative_plot(data,~Attrition,~DistanceFromHome)
Categorical_vs_quantitative_plot(data,~Attrition,~Education)
Categorical_vs_quantitative_plot(data,~Attrition,~EnvironmentSatisfaction)
Categorical_vs_quantitative_plot(data,~Attrition,~HourlyRate)
Categorical_vs_quantitative_plot(data,~Attrition,~JobInvolvement)
Categorical_vs_quantitative_plot(data,~Attrition,~JobLevel)
Categorical_vs_quantitative_plot(data,~Attrition,~JobSatisfaction)
Categorical_vs_quantitative_plot(data,~Attrition,~MonthlyIncome)
Categorical_vs_quantitative_plot(data,~Attrition,~MonthlyRate)
Categorical_vs_quantitative_plot(data,~Attrition,~NumCompaniesWorked)
Categorical_vs_quantitative_plot(data,~Attrition,~PerformanceRating)
Categorical_vs_quantitative_plot(data,~Attrition,~RelationshipSatisfaction)
Categorical_vs_quantitative_plot(data,~Attrition,~TotalWorkingYears)
Categorical_vs_quantitative_plot(data,~Attrition,~WorkLifeBalance)
Categorical_vs_quantitative_plot(data,~Attrition,~YearsAtCompany)
Categorical_vs_quantitative_plot(data,~Attrition,~YearsInCurrentRole)
Categorical_vs_quantitative_plot(data,~Attrition,~YearsSinceLastPromotion)
Categorical_vs_quantitative_plot(data,~Attrition,~YearsWithCurrManager)
```
# 3.3 Quantitative vs. Quantitative
```{r}
# scatterplot with linear fit line
ggplot(data,
       aes(x = TotalWorkingYears, 
           y = MonthlyIncome)) +
  geom_point(color= "steelblue") +
  geom_smooth(method = "lm")
# Age vs monthly income
ggplot(data,
       aes(x = Age, 
           y = MonthlyIncome)) +
  geom_point(color= "steelblue") +
  geom_smooth(method = "lm")
```
```{r}
fit1 <- lm(MonthlyIncome ~ TotalWorkingYears, data = data)
summary(fit1)
```
# Correlation Matrix:
```{r}
# # Let's have a better understanding about each feature through a correlation plot
options(repr.plot.width=10, repr.plot.height=7) 
nums <- select_if(data, is.numeric)
```

```{r}
library(ggcorrplot)
corr <- round(cor(nums), 1)

ggcorrplot(corr, 
           type = "lower", 
           lab = TRUE, 
           lab_size = 3, 
           method="square", 
           colors = c("tomato2", "white", "#01A9DB"), 
           title="Correlogram Employee Attritions", 
           ggtheme=theme_minimal())
```

```{r}
library(superheat)
superheat(nums, scale = TRUE)
```
```{r}
# sorted heat map
superheat(nums,
          scale = TRUE,
          left.label.text.size=3,
          bottom.label.text.size=3,
          bottom.label.size = .05,
          row.dendrogram = TRUE )
```
create a scatterplot matrix (long and not good visual)
```{r}
# create a scatterplot matrix (long and not good visual)
#library(GGally)
#ggpairs(nums)
```
# Radar chart

```{r}
head(data)
```
```{r}
 data %>% select_if(function(col) is.numeric(col) | 
                                   all(col == .$Attrition))
```

```{r}
plotdata <- data %>% 
            select_if(function(col) is.numeric(col) | all(col == .$Attrition)) %>% 
            rename(group = Attrition) %>%
            mutate_at(vars(-group),funs(rescale)) %>% 
            relocate(group,Age)
plotdata
```
```{r}
library(ggradar)
library(scales)
ggradar::ggradar(plotdata)
```

# px.parallel_coordinates chart
```{r}
#install.packages("parcoords")
library(parcoords)
```

```{r}
data_parrallel_plot <-  data %>% 
                          select_if(is.character) %>% 
                          relocate(Attrition, .after = last_col())
data_parrallel_plot
```

```{r}
parcoords(
 data_parrallel_plot,
 reorderable = T,
 brushMode = '1D-axes')
```


```{r}
library(GGally)
#set the value of alpha to 0.5
ggparcoord(data_parrallel_plot, columns=1:8, groupColumn = 9, alphaLines = 0.5)
```

```{r}
```


```{r}
```


# 3.4 Select column type for data processing

```{r}
# Get all character columns
data %>% 
  select_if(is.character)
# select_if(~!is.numeric(.))
```
```{r}
# Get all character columns
data %>% 
  select_if(is.numeric)
# select_if(~!is.numeric(.))
```
```{r}
class(colnames(data))
```
```{r}
list(colnames(data))
```

```{r}
for (i in list(colnames(data))){
  print(i)
}
```

# 4. Machine learning (ISTA 321)
```{r}
library(rsample)   # for data splitting
library(caret)     # for model packages
```
```{r}
path="WA_Fn-UseC_-HR-Employee-Attrition.csv"
data <- fread(path)
str(data)
```
# Delete unecessary columns
```{r}
data_reduce <-data %>% 
              dplyr::select(-Over18,-EmployeeNumber, -EmployeeCount)

dim(data_reduce)
```
# Getting dummy variables - one hot encoding

First, let’s create our dummy object that we’ll use for the conversion. We’ll use the dummyVars() function from caret. Note how the formula is churn ~ . This is telling it not to convert churn as that’s our target, but look at all the other features (that’s what the period does) and convert if needed. I’ve also specified fullRank = TRUE so that it automatically drops one factor level which we want. The level dropped is the reference level then.

```{r}
data_reduce_dummy <- dummyVars(Attrition ~ ., data = data_reduce, fullRank = TRUE)
data_reduce_dummy
```

```{r}
data_reduce <- predict(data_reduce_dummy, newdata = data_reduce)
data_reduce <- data.frame(data_reduce)
str(data_reduce)
```

```{r}
data_reduce
```
```{r}
Attrition_vals <- data %>% 
  dplyr::select(Attrition)
data_reduce <- cbind(data_reduce, Attrition_vals) # attach it back
data_reduce
```
# Dealing with nuances in model preferences

```{r}
data_reduce$Attrition <-  factor(ifelse(data_reduce$Attrition == 'Yes', 1, 0))
```
# Dealing with nuances in my preferences

When we one hot encoded it took the various levels found in the columns and then created column names that used those levels. The problem is that those values when in the columns had spaces, which it turned into periods in the column names. I can’t deal with periods and underscores in the same column names.
```{r}
colnames(data_reduce)
```
Let’s use some regex to replace all periods with underscores. Remember that period is a special character so you need to escape it with two backslashes ‘\’. I’m also going to add a ‘+’ to the end of my search string as ‘+’ tells it to look for one or more of the symbols. This way it’ll grab the double period too!
```{r}
library(stringr)
colnames(data_reduce) <- colnames(data_reduce) %>% stringr::str_replace_all('\\.+', '_')
colnames(data_reduce) # check!
```
# 4.3 Splitting into training and test sets
The caret package has function that makes this really easy. You can feed the function createDataPartition() your target, and your split ratio and it’ll give you back a list of row numbers that you can use to randomly select 80% of the data. Let’s see it in action.
```{r}
# Method 2 From ISTA 321
data_split <- createDataPartition(data_reduce$Attrition, p = 0.8, list = FALSE)
dim(data_reduce)
dim(data_split)
head(data_split, 10)

```
So what’s in this ts_split object? Looking at the first 10 values we see that there is a continuous index but then under Resample1 we see that there are some randomly missing values… those are the 20% that weren’t selected!
```{r}
features_train <- data_reduce[ data_split, !(names(data_reduce) %in% c('Attrition'))] 
dim(features_train)
```
```{r}
features_test <- data_reduce[ -data_split, !(names(data_reduce) %in% c('Attrition'))] 
dim(features_test)
```


```{r}
target_train <- data_reduce[ data_split, "Attrition"]
target_test <- data_reduce[-data_split, "Attrition"]

#check propation target
table(target_train)
table(target_test)
prop.table(table(target_train))
prop.table(table(target_test))
```

#  Centering and scaling
We’ll use the preProcess() function to do our preprocessing. What’s great is that we can tell it all the things we want it to do at once within method = In this case we’ll tell it to center, scale, and even use KNN to impute missing values.

```{r}
preprocess_object <- preProcess(features_train, 
                                  method = c('center', 'scale', 'knnImpute'))
preprocess_object # We can look at the object and it'll tell us what it did
```
Now we can use ’predict()` to apply that preprocess object to our data (just like we used predict for creating our dummy variables).
```{r}
features_train <- predict(preprocess_object, newdata = features_train)
features_test <- predict(preprocess_object, newdata = features_test)
```
A quick histogram shows that Age has been scaled
```{r}
hist(features_train$Age)
```

# Fitting our models

Fitting a kNN model
```{r}
knn_fit <- knn3(features_train, target_train, k = 5)
knn_fit # just check it
```


```{r}
knn_pred <- predict(knn_fit, features_test, type = 'class' )
predictions <- cbind(data.frame(target_test, knn_pred))
summary(predictions)
```
```{r}
confusionMatrix(knn_pred, target_test)
```

Fitting a logistic regression model
```{r}
full_train <- cbind(features_train, target_train)
#glimpse(full_train)
```


```{r}
log_train <- glm(target_train ~ ., family = 'binomial', data = full_train)
summary(log_train)
```
Alright, now predict our test targets using our test features. Use type = 'response' so R knows to give you back the probability.

```{r}
log_pred <- predict(log_train, newdata = features_test, type = 'response')
head(log_pred) # just look at the first few values... note the 0-1 scale.
```
We can convert these probabilities to classes. In this case anything greater than or equal to 0.5 is a 1 and everything else a 0.

```{r}
log_pred <- ifelse(log_pred >= 0.5, 1, 0)
```

```{r}
predictions$log_pred <- factor(log_pred)
summary(predictions)
```


```{r}
confusionMatrix(factor(log_pred), target_test)
```

Fitting a linear discriminant analysis (LDA) model
```{r}
full_train[[37]]
```

```{r}
library(MASS) # Load mass - install if needed
lda_train <- lda(target_train ~ ., data = full_train) # fit model
lda_pred <- predict(lda_train, newdata = features_test, type = 'response') # predict
predictions$lda_pred <- lda_pred$class # add predictions to data frame
summary(predictions)
```

# 4. Mahicne learning model (ML BOOK)
```{r}
library(rsample)   # for data splitting
# Modeling packages
library(caret)     # for logistic regression modeling
# Model interpretability packages
library(vip)       # variable importance
```

```{r}
path="WA_Fn-UseC_-HR-Employee-Attrition.csv"
data <- fread(path)
dim(data)
```
Remove unnessary columns:
```{r}
data <-data %>%dplyr::select(-Over18,-EmployeeNumber, -EmployeeCount)
dim(data)
str(data)
```
Convert all character columns to factor
```{r}
# all character columns to factor:
data <- mutate_if(data, is.character, as.factor)
str(data)
```


```{r}
# Create training (70%) and test (30%) sets for the 
# rsample::attrition data.
set.seed(123)  # for reproducibility
churn_split <- initial_split(data, prop = .7, strata = "Attrition")
churn_train <- training(churn_split)
churn_test  <- testing(churn_split)
```
# Multiple logistic regression
# MLP khong su dung preprocess
```{r}
set.seed(123)
cv_model <- train(
  Attrition ~ ., 
  data = churn_train, 
  method = "glm",
  family = "binomial",
  trControl = trainControl(method = "cv", number = 5)
)
```


```{r}
summary(cv_model)
```


```{r}
# predict class
pred_class <- predict(cv_model, churn_train)
# create confusion matrix
confusionMatrix(
  data = pred_class, 
  reference = churn_train$Attrition
)
# NOTE: dung theo kieu nay khong duoc do hieu nham positive class la No, sensitivity, specificity, pos , neg lon nguoc so voi binh thuong
```

```{r}
pred_class <- predict(cv_model, churn_train)
# create confusion matrix (pp chuan phai relevel)
confusionMatrix(
  data = relevel(pred_class, ref = "Yes"), 
  reference = relevel(churn_train$Attrition, ref = "Yes")
)
```


```{r}
library(ROCR)
# Compute predicted probabilities
m1_prob <- predict(cv_model, churn_train, type = "prob")$Yes

# Compute AUC metrics for cv_model1 and cv_model3
perf1 <- prediction(m1_prob, churn_train$Attrition) %>%
  performance(measure = "tpr", x.measure = "fpr")

# Plot ROC curves for cv_model1 and cv_model3
plot(perf1, col = "black", lty = 2)

```


```{r}
vip(cv_model, num_features = 20)
```
Note: Neu chuyen cac column Job satisfaction tu int (1,2,3,4) thanh factor (low, normal, high) thi important feature explain se dien giai chinh xac column + factor tuong ung, vd: Job satisfaction Very_high, Job satisfaction _ Normal 

# MLP Su dung preprocess 
```{r}
set.seed(123)
cv_model <- train(
  Attrition ~ ., 
  data = churn_train, 
  method = "glm",
  family = "binomial",
  preProcess = c("zv", "center", "scale"), # loai bo near zero/constant column, center and scale column value
  trControl = trainControl(method = "cv", number = 5)
)
```

```{r}
pred_class <- predict(cv_model, churn_train)
# create confusion matrix (pp chuan phai relevel)
confusionMatrix(
  data = relevel(pred_class, ref = "Yes"), 
  reference = relevel(churn_train$Attrition, ref = "Yes")
)
```

```{r}
library(ROCR)
# Compute predicted probabilities
m1_prob <- predict(cv_model, churn_train, type = "prob")$Yes

# Compute AUC metrics for cv_model1 and cv_model3
perf1 <- prediction(m1_prob, churn_train$Attrition) %>%
  performance(measure = "tpr", x.measure = "fpr")

# Plot ROC curves for cv_model1 and cv_model3
plot(perf1, col = "black", lty = 2)
```


```{r}
vip(cv_model, num_features = 20)
```

#  GBM from library gbm


```{r}
# Read data
path="WA_Fn-UseC_-HR-Employee-Attrition.csv"
data <- fread(path)
dim(data)

# Remove unnessary columns:
data <-data %>%dplyr::select(-Over18,-EmployeeNumber, -EmployeeCount)
# all character columns to factor:
data <- mutate_if(data, is.character, as.factor)
data$Attrition<-ifelse(data$Attrition=="Yes", 1, 0)
# Create training (80%) and test (20%) sets for the 
set.seed(430)
churn_split = createDataPartition(data$Attrition, p =0.8, list = FALSE)
churn_train = data[churn_split, ]
churn_test = data[-churn_split, ]
dim(churn_train)
dim(churn_test)

```
```{r}
head(churn_train)
```


```{r}
library(gbm)      # for original implementation of regular and stochastic GBMs
```

 Zero- and Near Zero-Variance Predictors
```{r}
nzv <- nearZeroVar(churn_train)
nzv
```
```{r}
head(churn_train[[24]])
```

```{r}
churn_train[,-nzv]
```

```{r}
nzv <- nearZeroVar(churn_train)
print(nzv)
churn_train_nzv <- churn_train[,-24]
dim(churn_train)
dim(churn_train_nzv)
```

```{r}
set.seed(123)  # for reproducibility
gbm.model <- gbm(
  formula = Attrition ~ .,
  data = churn_train_nzv,
  distribution = "bernoulli",  # SSE loss function
  n.trees = 1000,
  shrinkage = 0.1,
  interaction.depth = 3,
  n.minobsinnode = 10,
  cv.folds = 5
)
```

```{r}
print(gbm.model )
```

```{r}
best.iter = gbm.perf(gbm.model, method="cv")
best.iter
```

```{r}
summary(gbm.model)
```
```{r}
library(vip)
vip(gbm.model)
```

```{r}
plot.gbm(gbm.model, 1, best.iter)
plot.gbm(gbm.model, 2, best.iter) 
plot.gbm(gbm.model, 3, best.iter)
plot.gbm(gbm.model, 4, best.iter)
```

# GBM from Caret package

```{r}
# Read data
path="WA_Fn-UseC_-HR-Employee-Attrition.csv"
data <- fread(path)
dim(data)

# Remove unnessary columns:
data <-data %>%dplyr::select(-Over18,-EmployeeNumber, -EmployeeCount)
# all character columns to factor:
data <- mutate_if(data, is.character, as.factor)
#data$Attrition<-ifelse(data$Attrition=="Yes", 1, 0)
# Create training (80%) and test (20%) sets for the 
set.seed(430)
churn_split = createDataPartition(data$Attrition, p =0.8, list = FALSE)
churn_train = data[churn_split, ]
churn_test = data[-churn_split, ]
dim(churn_train)
dim(churn_test)
```
```{r}
churn_train_nzv <- churn_train[,-24]
```

Note: Target must be factor char, not numeric. Not include near zero
```{r}

set.seed(123)
fitControl = trainControl(method="cv", number=5, returnResamp = "all")

model2 = train(Attrition~., 
               data=churn_train_nzv, 
               method="gbm",
               distribution="bernoulli",
               trControl=fitControl, 
               verbose=F
    )
```

```{r}
model2
```
```{r}
confusionMatrix(model2)
```
```{r}
churn_test_nzv <- churn_test[,-24]
mPred = predict(model2, churn_test_nzv, na.action = na.pass)
postResample(mPred, churn_test_nzv$Attrition)
```


```{r}
confusionMatrix(mPred, churn_test_nzv$Attrition)
# Note: need to change positive class to Yes
```
# XGBOOST
```{r}
library(xgboost)
```


```{r}
# Read data
path="WA_Fn-UseC_-HR-Employee-Attrition.csv"
data <- fread(path)
dim(data)

# Remove unnessary columns:
data <-data %>%dplyr::select(-Over18,-EmployeeNumber, -EmployeeCount)
# all character columns to factor:
data <- mutate_if(data, is.character, as.factor)
#data$Attrition<-ifelse(data$Attrition=="Yes", 1, 0)
# Create training (80%) and test (20%) sets for the 
set.seed(430)
churn_split = createDataPartition(data$Attrition, p =0.8, list = FALSE)
churn_train = data[churn_split, ]
churn_test = data[-churn_split, ]
dim(churn_train)
dim(churn_test)
```
Up to this point, we dealt with basic data cleaning and data inconsistencies. To use xgboost package, keep these things in mind:
1. Convert the categorical variables into numeric using one hot encoding
2. For classification, if the dependent variable belongs to class factor, convert it to numeric
```{r}
train_labels <- churn_train$Attrition 
test_label <- churn_test$Attrition

new_train <- model.matrix(~.+0,data = churn_train[,-c("Attrition"),with=F]) 
new_test <- model.matrix(~.+0,data = churn_test[,-c("Attrition"),with=F])

#convert factor to numeric 
train_labels <- as.numeric(train_labels)-1
test_label <- as.numeric(test_label)-1
```

```{r}

dtrain <- xgb.DMatrix(data = new_train,label = train_labels) 
dtest <- xgb.DMatrix(data = new_test,label=test_label)
```


```{r}
#default parameters
params <- list(booster = "gbtree", objective = "binary:logistic", eta=0.3, gamma=0, max_depth=6, min_child_weight=1, subsample=1, colsample_bytree=1)
```


```{r}
xgbcv <- xgb.cv( params = params, data = dtrain, nrounds = 100, nfold = 5, showsd = T, stratified = T, print.every.n = 10, early.stop.round = 20, maximize = F)
##best iteration = 79
```

```{r}
min(xgbcv$test.error.mean)
```

```{r}
xgb1 <- xgb.train (params = params, data = dtrain, nrounds = 79, watchlist = list(val=dtest,train=dtrain), print.every.n = 10, early.stop.round = 10, maximize = F , eval_metric = "error")
```

```{r}
#model prediction
xgbpred <- predict (xgb1,dtest)
xgbpred <- ifelse (xgbpred > 0.5,1,0)
```

```{r}
class(test_label)
class(xgbpred)
```

```{r}
#confusion matrix
confusionMatrix(as.factor(xgbpred), as.factor(test_label))
```
```{r}
#view variable importance plot
mat <- xgb.importance (feature_names = colnames(new_train),model = xgb1)
xgb.plot.importance (importance_matrix = mat[1:20]) 
```
# GBM from H20 package
```{r}
# Read data
path="WA_Fn-UseC_-HR-Employee-Attrition.csv"
data <- fread(path)
dim(data)

# Remove unnessary columns:
data <-data %>%dplyr::select(-Over18,-EmployeeNumber, -EmployeeCount)
# all character columns to factor:
data <- mutate_if(data, is.character, as.factor)
#data$Attrition<-ifelse(data$Attrition=="Yes", 1, 0)
# Create training (80%) and test (20%) sets for the 
set.seed(430)
churn_split = createDataPartition(data$Attrition, p =0.8, list = FALSE)
churn_train = data[churn_split, ]
churn_test = data[-churn_split, ]
dim(churn_train)
dim(churn_test)
```

```{r}
# create feature names
y <- "Attrition"
x <- setdiff(names(churn_train), y)
```

```{r}
library(h2o)
h2o.no_progress()
h2o.init(max_mem_size = "5g")
```


```{r}
# turn training set into h2o object
train.h2o <- as.h2o(churn_train)

```


```{r}
# training basic GBM model with defaults
h2o.fit1 <- h2o.gbm(
  x = x,
  y = y,
  training_frame = train.h2o,
  nfolds = 5
)

# assess model results
h2o.fit1
```
Similar to XGBoost, we can incorporate automated stopping so that we can crank up the number of trees but terminate training once model improvement decreases or stops. There is also an option to terminate training after so much time has passed (see max_runtime_secs). In this example, I train a default model with 5,000 trees but stop training after 10 consecutive trees have no improvement on the cross-validated error. In this case, training stops after 3828 trees and has a cross-validated RMSE of $24,684.

Must drop constant columns before H2O
```{r}
train.h2o_nzv <- train.h2o[,-24]
```

```{r}
# create feature names
y <- "Attrition"
x <- setdiff(names(train.h2o_nzv), y)
```

```{r}
# training basic GBM model with defaults
h2o.fit2 <- h2o.gbm(
  x = x,
  y = y,
  training_frame = train.h2o_nzv,
  nfolds = 5,
  ntrees = 5000,
  stopping_rounds = 10,
  stopping_tolerance = 0,
  seed = 123
)

# model stopped after xx trees
h2o.fit2@parameters$ntrees
```


```{r}
h2o.fit2
```
```{r}
# cross validated RMSE
h2o.rmse(h2o.fit2, xval = TRUE)
```
```{r}
h2o.varimp_plot(h2o.fit2, num_of_features = 10)
```
```{r}
h2o.partialPlot(h2o.fit2, data = train.h2o, cols = "MonthlyIncome")
```
```{r}
# get a few observations to perform local interpretation on
# convert test set to h2o object
test.h2o <- as.h2o(churn_test)
test.h2o_nzv <- test.h2o[,-24]
local_obs <- test.h2o_nzv[1:2, ]
local_obs
# apply LIME
library(lime)
explainer <- lime(churn_train_nzv, h2o.fit2)
explainer
explanation <- explain(local_obs, explainer, n_features = 5)
plot_features(explanation)
```
Predict
```{r}
# convert test set to h2o object
test.h2o <- as.h2o(churn_test)
test.h2o_nzv <- test.h2o[,-24]
```


```{r}
# evaluate performance on new data
h2o.performance(model = h2o.fit2, newdata = test.h2o)
```


```{r}
predict_value <-h2o.predict(h2o.fit2, newdata = test.h2o)
```

```{r}
predict_value$predict
test.h2o$Attrition
class(predict_value$predict)
class(test.h2o$Attrition)
```
```{r}
class(test.h2o$Attrition)
class(as.factor(test.h2o$Attrition))
```


```{r}
confusionMatrix(as.factor(predict_value$predict),as.factor(test.h2o$Attrition))
```

# 5 ML Follow statistic machine learning BOOK

```{r}
# Read data
path="WA_Fn-UseC_-HR-Employee-Attrition.csv"
data <- fread(path)
dim(data)
# Remove unnessary columns:
data <-data %>%dplyr::select(-Over18,-EmployeeNumber, -EmployeeCount)
# all character columns to factor:
data <- mutate_if(data, is.character, as.factor)
# Create training (70%) and test (30%) sets for the 
# rsample::attrition data.
set.seed(123)  # for reproducibility
churn_split <- initial_split(data, prop = .8, strata = "Attrition")
churn_train <- training(churn_split)
churn_test  <- testing(churn_split)
dim(churn_train)
dim(churn_test)
```
At first glance, it might appear as if the use of createDataPartition() is no different than our previous use of sample(). However, createDataPartition() tries to ensure a split that has a similar distribution of the supplied variable in both datasets. See the documentation for details.

```{r}
set.seed(430)
churn_split = createDataPartition(data$Attrition, p =0.8, list = FALSE)
churn_train = data[churn_split, ]
churn_test = data[-churn_split, ]
dim(churn_train)
dim(churn_test)
```
# Simple additive logistic regression.

```{r}
glm_mod = train(
  form = Attrition ~ .,
  data = churn_train,
  trControl = trainControl(method = "cv", number = 5),
  method = "glm",
  family = "binomial"
)
glm_mod
```

```{r}
#summary(glm_mod)
```

```{r}
pred_class <- predict(glm_mod, churn_test)
# create confusion matrix (pp chuan phai relevel)
confusionMatrix(
  data = relevel(pred_class, ref = "Yes"), 
  reference = relevel(churn_test$Attrition, ref = "Yes")
)
```
# KNN
```{r}
knn_mod = train(
  Attrition ~ .,
  data = churn_train,
  method = "knn",
  trControl = trainControl(method = "cv", number = 5)
)
knn_mod
```
Here we are again using 5-fold cross-validation and no pre-processing. Notice that we now have multiple results, for k = 5, k = 7, and k = 9.

Let’s modifying this training by introducing pre-processing, and specifying our own tuning parameters, instead of the default values above.

Perprocess nzv: For some other models, this might be an issue (especially if we resample or down-sample the data). We can add a filter to check for zero- or near zero-variance predictors prior to running the pre-processing calculations:
```{r}
knn_mod = train(
  Attrition ~ .,
  data = churn_train,
  method = "knn",
  trControl = trainControl(method = "cv", number = 5),
  preProcess = c("nzv","center", "scale"),
  tuneGrid = expand.grid(k = seq(1, 101, by = 2))
)
```


```{r}
head(knn_mod$results, 5)
```


```{r}
plot(knn_mod)
```


```{r}
knn_mod$bestTune
```


```{r}
pred_class <- predict(knn_mod, churn_test)
# create confusion matrix (pp chuan phai relevel)
confusionMatrix(
  data = relevel(pred_class, ref = "Yes"), 
  reference = relevel(churn_test$Attrition, ref = "Yes")
)
```


```{r}

```


```{r}
```


```{r}
```

