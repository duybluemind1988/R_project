---
title: "Untitled"
output: html_document
---
# Encoding predictors with many Categories
```{r}

library(tidymodels)
library(FeatureHashing)
library(stringr)

options(width = 150)
```


```{r}
# Create example data ----------------------------------------------------------

load("../Data_Sets/OkCupid/okc.RData")
okc_train
```
```{r}

# Make small example data set

sample_towns <- c(
  'alameda', 'belmont', 'benicia', 'berkeley', 'castro_valley', 'daly_city', 
  'emeryville', 'fairfax', 'martinez', 'menlo_park', 'mountain_view', 'oakland', 
  'other', 'palo_alto', 'san_francisco', 'san_leandro', 'san_mateo', 
  'san_rafael', 'south_san_francisco', 'walnut_creek'
)

location <- 
  okc_train %>% 
  dplyr::select(where_town) %>% 
  distinct(where_town) %>% 
  arrange(where_town)
location
```


```{r}
# Create hash features using binary representations

binary_hashes <-
  hashed.model.matrix(
    ~ where_town,
    data = location,
    hash.size = 2 ^ 4,
    signed.hash = FALSE,
    create.mapping = TRUE
  )
binary_hashes

```


```{r}
binary_mapping <- hash.mapping(binary_hashes)
binary_mapping
```


```{r}
names(binary_mapping) <- str_remove(names(binary_mapping), "where_town")
binary_calcs <- 
  binary_mapping %>% 
  enframe() %>% 
  set_names(c("town", "column_num_16")) %>% 
  mutate(integer_16 = hashed.value(names(binary_mapping))) %>% 
  dplyr::filter(town %in% sample_towns) %>% 
  arrange(town)
binary_calcs
```


```{r}
binary_df <- 
  binary_hashes %>% 
  as.matrix() %>% 
  as_tibble() %>% 
  bind_cols(location) %>% 
  dplyr::rename(town = where_town) %>% 
  dplyr::filter(town %in% sample_towns) %>% 
  arrange(town)
binary_df
```


```{r}
# Create hash features using signed integer representations

signed_hashes <-
  hashed.model.matrix(
    ~ where_town,
    data = location,
    hash.size = 2 ^ 4,
    signed.hash = TRUE
  )

signed_df <- 
  signed_hashes %>% 
  as.matrix() %>% 
  as_tibble() %>% 
  bind_cols(location) %>% 
  dplyr::rename(town = where_town) %>% 
  dplyr::filter(town %in% sample_towns) %>% 
  arrange(town)

# TODO update links
# Table 5.4
# https://bookdown.org/max/FES/encoding-predictors-with-many-categories.html#tab:categorical-hash-values
signed_df
```

# Supervised encoding methods
```{r}
# Code requires these packages: 
#install.packages("rlang")
library(tidymodels)
library(embed)
library(plotly)
library(gridExtra)

options(width = 120)
```


```{r}
# Create example data ----------------------------------------------------------

load("../Data_Sets/OkCupid/okc.RData")
load("../Data_Sets/OkCupid/okc_binary.RData")
```

```{r}
# Partial pooling example ------------------------------------------------------

partial_rec <- 
  recipe(Class ~ ., data = okc_train) %>%
  step_lencode_bayes(
    where_town,
    outcome = vars(Class),
    verbose = FALSE,
    options = list(
      chains = 5, 
      iter = 1000, 
      cores = min(parallel::detectCores(), 5),
      seed = 18324
    )
  ) %>%
  prep()
```


```{r}
# Get raw rates and log-odds
okc_props <- 
  okc_train %>%
  group_by(where_town) %>%
  summarise(
    rate = mean(Class == "stem"),
    raw  = log(rate/(1-rate)),
    n = length(Class)
  ) %>%
  mutate(where_town = as.character(where_town))

okc_props
```


```{r}
# Embedding methods ------------------------------------------------------------

# Get the keyword columns
keywords <- names(okc_train_binary)[-1]
```


```{r}
# Merge the basic OkC data with the keyword indicators
okc_embed <-
  okc_train %>% 
  dplyr::select(Class, where_town, profile) %>%
  full_join(okc_train_binary, by = "profile")
```


```{r}
# Tensorflow wants doubles instead of binary integers
okc_embed[, keywords] <- apply(okc_embed[, keywords], 2, as.numeric)
```


```{r}
# Use the entity embedding for supervised learning
set.seed(355)
nnet_rec <- 
  recipe(Class ~ ., data = okc_embed) %>% 
  step_embed(
    where_town,
    outcome = vars(Class),
    num_terms = 3,
    hidden_units = 10,
    predictors = vars(!!!keywords),
    options = embed_control(
      loss = "binary_crossentropy",
      epochs = 30,
      validation_split = 0.2,
      verbose = 0
    )
  ) %>%
  prep()
```


```{r}
# Organize results -------------------------------------------------------------

partial_pooled <- 
  tidy(partial_rec, number = 1) %>%
  dplyr::select(-terms, -id) %>%
  setNames(c("where_town", "partial"))

word_embed <- 
  tidy(nnet_rec, number = 1) %>%
  dplyr::select(-terms, -id) %>%
  setNames(c(paste0("Feature", 1:3), "where_town"))

all_est <- 
  partial_pooled %>%
  full_join(okc_props, by = "where_town") %>%
  inner_join(word_embed, by = "where_town") %>%
  dplyr::select(where_town, rate, n, raw, partial, Feature1, Feature2, Feature3)

odds_rng <- extendrange(c(all_est$raw, all_est$partial), f = 0.01)
```


```{r}
# Figure 5.2 -------------------------------------------------------------------
# https://bookdown.org/max/FES/categorical-supervised-encoding.html#fig:categorical-log-odds


odds_1 <- 
  ggplot(all_est) +
  aes(x = raw, y = partial, size = log10(n)) + 
  scale_size(range = c(.1, 6)) +
  geom_abline(alpha = .4, lty = 2)  +
  xlim(odds_rng) +
  ylim(odds_rng) +
  xlab("Raw Log-Odds") +
  ylab("Shrunken Log-Odds") + 
  geom_point(aes(text = gsub("_", " ", where_town)), alpha = .4)


odds_2 <- 
  ggplot(all_est) +
  aes(x = .5*(raw + partial), y = raw - partial, size = log10(n)) + 
  scale_size(range= c(.1, 6)) + 
  geom_hline(alpha = .4, lty = 2, yintercept = 0) + 
  xlab("Average Estimate") +
  ylab("Raw - Shrunken") + 
  geom_point(aes(text = gsub("_", " ", where_town)), alpha = .4)

odds_1 <- ggplotly(odds_1, tooltip = "text")
odds_2 <- ggplotly(odds_2, tooltip = "text") 
```


```{r}
```


```{r}
```


```{r}
```


```{r}
```


```{r}
```

